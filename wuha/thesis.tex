\documentclass[a4paper,12pt,twoside]{report}
\input{math_commands.tex} % math commands from https://github.com/goodfeli/dlbook_notation
\usepackage{acronym}
\usepackage{url}
\usepackage{cite}
\usepackage{listings}
\usepackage[pdftex]{graphicx}
\usepackage[hang,small,bf]{caption}
\usepackage{styles/tum}
\usepackage{setspace}
\usepackage[german,english]{babel}
\usepackage{float}
\usepackage{floatflt}
\usepackage{fancyhdr}
\usepackage{color}
\usepackage{booktabs}
\usepackage[pdftex,bookmarks=true,plainpages=false,pdfpagelabels=true]{hyperref}	%TODO make yourself familiar with \label, \ref and \hyperref for referencing figures, tables, chapters, etc.
\usepackage{mdwlist}
\usepackage{enumerate}
\usepackage{array}
\usepackage{longtable}
\usepackage[utf8]{inputenc}
\usepackage{wasysym}
\usepackage[capitalize, noabbrev]{cleveref}


\usepackage{subcaption}

% Path for graphics
\graphicspath{{figures/}}

\begin{document}
\setlength{\evensidemargin}{22pt}
\setlength{\oddsidemargin}{22pt}

\def\doctype{Bachelor's Thesis}
\def\faculty{Informatik}
\def\title{Perceptual Losses for Deep Learning on Fluid Simulations}		%TODO add title in English
\def\titleGer{Perceptual Losses für Deep Learning von Flüssigkeitssimulationen}	%TODO add title in German
\def\supervisor{Prof.\ Dr.\  Nils Thürey}
\def\advisor{M.Sc.\ Georg Kohl}
\def\author{Hanfeng Wu}			%TODO add author name
\def\date{15.09.2021}		%TODO add submission / handover date


\hypersetup{pdfborder={0 0 0},
                        pdfauthor={<author>},
                        pdftitle={thesis-ba-wenjie},
                        }

\lstset{showspaces=false, numbers=left, frame=single, basicstyle=\small}

\pagenumbering{alph}

\include{pages/cover}
\include{pages/titlepage}
\newpage
\thispagestyle{empty}
\mbox{}
\include{pages/disclaimer}		%TODO choose one of 'diploma | bachelor's | master's thesis' in the disclaimer file

\newpage
\thispagestyle{empty}
\mbox{}

\chapter*{Acknowledgements}


\pagenumbering{roman}

\selectlanguage{english}
\begin{abstract}

%abstract english

This thesis studies the integration of perceptual loss into several models that are related to fluid simulation. Perceptual losses are used to compare high level differences, while traditional loss functions like MSE and MAE only compare the pixel level differences which is more brute force. 

Now some famous perceptual loss functions like comparing the intermediate layers of pretrained vgg network already improve its performance in some image related tasks.\cite{johnson2016perceptual} We want to show that in the context of fluid simulation, the integration of some pretrained perceptual losses should also outperform the traditional loss functions.

We tested some fluid simulation tasks in SOL\cite{um2020sol} to improve the performance of the percetual loss functions. Meanwhile we also integrate such loss functions into models like autoencoder and superresolution to compare their results with those from the same models but trained by MSE loss functions

Finally we combined the result of SOL and superresolution model to conduct some fluid simulations at a lower cost to show the advantage of integrating perceptual losses in such tasks.

\end{abstract}

\clearpage

\selectlanguage{german}
\begin{abstract}

Diese Dissertation untersucht die Integration von Wahrnehmungsverlusten in verschiedene Modelle, die sich auf die Fluidsimulation beziehen. Wahrnehmungsverluste werden verwendet, um Unterschiede auf hohem Niveau zu vergleichen, während herkömmliche Verlustfunktionen wie MSE und MAE nur die Pixelniveauunterschiede vergleichen, was roher ist.

Einige berühmte Wahrnehmungsverlustfunktionen wie der Vergleich der Zwischenschichten eines vortrainierten VGG-Netzwerks verbessern bereits seine Leistung bei einigen bildbezogenen Aufgaben.\cite{johnson2016perceptual} Wir wollen zeigen, dass die Integration einiger vortrainierter Wahrnehmungsverluste im Kontext der Fluidsimulation übertreffen auch die traditionellen Verlustfunktionen.

Wir haben einige Fluidsimulationsaufgaben in SOL\cite{um2020sol} getestet, um die Leistung der Percetual Loss Functions zu verbessern. Inzwischen integrieren wir solche Verlustfunktionen auch in Modelle wie Autoencoder und Superresolution, um deren Ergebnisse mit denen aus den gleichen Modellen zu vergleichen, die jedoch mit MSE-Verlustfunktionen trainiert wurden

Schließlich haben wir die Ergebnisse von SOL und Superauflösungsmodell kombiniert, um einige Fluidsimulationen zu geringeren Kosten durchzuführen, um den Vorteil der Integration von Wahrnehmungsverlusten in solchen Aufgaben zu zeigen.
%abstract german
\textit{Note: Insert the German translation of the English abstract here.}

\end{abstract}

\clearpage

\selectlanguage{english}


\tableofcontents
\clearpage

\clearpage

\begin{acronym}
\acro{SOL}{Solver in the Loop}
\acro{LSIM}{Learning Similarity Metrics for Numerical Simulations}

\end{acronym}

\pagenumbering{arabic}

\fancyhead{}
\pagestyle{fancy}
\fancyhead[LE]{\slshape \leftmark}
\fancyhead[RO]{\slshape \rightmark}
\headheight=15pt




%------- chapter 1 -------

\chapter{Introductions}

Our main purpose of this paper is to demonstrate the advantage of adopting the perceptual loss functions in various deep learning tasks on fluid simulation. We try to show statistically and perceptually that by integrating suitable perceptual loss functions in such tasks can outperform the original model trained on traditional loss functions such as MSE and MAE. In the end we will also compare the performance and outputs of running solely the simulation and the simulation combined with some deep learning models.
\section{Fluid simulation}
\subsection{Navier Stokes Equation}
The state of art Fluid simulation is based on the famous incompressible equation Navier-Stokes equation

\begin{equation}
\frac{\partial \vec u}{\partial t}+\vec u\cdot \nabla\vec u+\frac1\rho\nabla p = \vec g + \nu\nabla\cdot\nabla\vec{u}
\end{equation}

\begin{equation}
{\nabla}\cdot\vec{u} = 0
\end{equation}

where $\nabla$ denotes the gradient, $\nabla\cdot$ denotes the Divergence, $\vec{u}$ denotes the velocity of the fluid, $t$ denotes the time step, $\rho$ denotes the density of the fluid, $p$ denotes the pressure, $\vec{g}$ denotes the gravity and $\nu$ denotes the viscosity of the fluid.

The equation (1.1) is actually a transformation of the $\vec{F} = m\vec{a}$ and the equation (1.2) describes the incompressibility of the fluid.
\subsection{Grid Stucture}
The way of storing the velocity and the density is based on two different grid structure. We store the dencity in the center of each cell, we call it centeredgrid or scalar grid. However for storing the velocity, we sample them at the face centers of each cell\cite{doi:10.1063/1.1761178}. In such way we can more easily compute the inflow and outflow of each grid for each direction, however as a trade off, the data format would be more complex than normal centeredgrid, and we usually have to stack each verlocity array of each dimension together and also adopt them individually in some computations(e.g. computing loss function in deep learning)

\begin{figure}[h]
\centering
\includegraphics[width=\textwidth]{Staggered.png}
\caption{Staggered grid format}
\end{figure}

\subsection{Advection}
With the knowledge base of the NS-equation and grid structures we now need the advection algorithm to run the simulation. We adopt the semi-lagrangian advection algorithm. In the lagrangian point of view, if we want to compute the grid value of the n+1 time step of grid position $\vec{x_G}$, we should figure out which particle actually flows to the grid $\vec{x_G}$ from time step n+1. If we name the grid position of the particle as $\vec{x_P}$, then the new particle at time step n+1 in $\vec{x_G}$ should have the same physical property as the particle at time step n in $\vec{x_P}$

\begin{figure}[h]
\centering
\includegraphics[scale=0.5]{advection.png}
\caption{advection}
\end{figure}

we first use the euler equation to calculate the $\vec{x_P}$ as a step before of $\vec{x_G}$
\begin{equation}
\vec x_P=\vec x_G-\Delta t\frac{d\vec x_G}{dt}
\end{equation}

because $\frac{d\vec x}{dt}=\vec u(\vec x)$ we have

\begin{equation}
\vec x_P=\vec x_G-\Delta t\vec u(\vec x_G)
\end{equation}
where $\vec u(\vec x_G)$ denotes the velocity sampled at the position $x_G$, with the advection we can update the velocity, pressure and density of the whole vector field.

with all the knowledge above, we can formulate a sequence to conduct the basic fluid simulation.

$\\\bullet$ start with an initial velocity field $\vec{u}^{0}$ with the property ${\nabla}\cdot\vec{u} = 0$
$\\\bullet$ choose a time step $\Delta t$ 
$\\\bullet$ For time step n = 0, 1, 2, ...
\par$\bullet$  $\vec{u}^{A} = advect(\vec{u}^{n}, \vec{u}^{n}, \Delta t)$
 \par$\bullet$  add the extra force $\vec{u}^{B} = \vec{u}^{A} + \Delta t\vec{g}$
 \par$\bullet$  $\vec{u}^{n+1} =make\_incompressible(\Delta t, \vec{u}^{B})$


\section{Deep learning tasks}
There are also various ways of integrating deep learning models into the fluid simulation.
\subsection{Autoencoder}
The Autoencoder model has a bottle neck shape, which aims to produce the same output as the input. Once trained, the Autoencoder model can be saparated into two parts, namely the encoder and the decoder, which can compress the image with the encoder and later decompress the image with the decoder to its forer shape.
\subsection{Superresolution}
With the superresolution model, we can upscale the low-resolution images to high-resolution images, which based on that we have fed lots of similar data to the model. In this paper, we apply the Superresolution model at the end of the Solver in the Loop model in order to boost the fluid simulation while still obtain a fairly similar output.
\subsection{Solver in the Loop}
When we want to perform our fluid simulation on a lower-resolution domain to decrease the time cost, we always suffer from the numerical error comparing to the simulation running on the higher-resolution domain. It is reasonable because with the same initial state, the vector field on the higher domain has richer information than the one sampled in the lower domain. Dr.\ Kiwon Um\cite{um2020sol} developed a mechanisim to learn the difference between the 2 different domains to reduce the numerical error.

\section{Perceptual loss functions}
Perceptual loss functions are used when comparing two images, they are not like traditional loss functions like MSE or MAE which only computes the low level pixel differences. Perceptual losses on the other hand, are normally forward networks trained for specific tasks. For example, VGG-16 network was trained for massive image classification, and LSIM was trained on smoke and fluid simulations. When adopting those networks, we can either compute the mse loss between the intermediate layers of the trained network, or directly passing it through depending on the goal of the chosen perceptual loss network. These perceptual loss networks tries to retrieve the high level differences between the images, hence will usually have a better performance than the traditional loss functions. In a word, traditional loss functions have more general use cases, while perceptual loss functions will achieve better performance on specific tasks.
In this paper we mainly focus on comparing the performance between traditional loss function MSE and perceptual loss functions LSIM, VGG-16 and lpips.




\chapter{Related Work}
similar goal area methods


%------- chapter 2 -------

\chapter{Metrics and Perceptual Losses}

In this chapter we will cover several loss functions that we adopted in this paper and briefly explain their characteristics and their drawbacks. More percise integrations and results will be convered in the chapter 5.

\section{Mean Squre Error}

MSE is one of the most widely used loss functions.
\begin{equation}
{MSE}=\frac{1}{n}\sum_{i=1}^n(Y_i-\hat{Y_i})^2
\end{equation}
Where ${Y}$ is the reference tensor and $\hat{Y}$ is the predicted tensor based on the trainable parameters. With this loss function being adopted, the network will try to do the gradient decent on the weights in a way that can achieve minimum square error. The optimal case is that the predicted tensor $\hat{Y}$ is exactly the same is the reference tensor ${Y}$. We can see that the core idea for the MSE is very general so that this loss function can be applied almost for any models, however the MSE loss function is not suitable for some image related tasks. If the two inputs of the MSE loss function is merely a image with its core content shifted by some pixels, the MSE will produce a very high value, which is not representitive, in another word, the MSE does not have shift or rotate invariance. 

Besides, MSE computes the squre error of the two tensors, which means that MSE is also prone to the outliers, beacause when it has a very large outlier in the tensor, the result of MSE loss function will be strongly influenced, so in most image construction cases, in order to achieve a lower square error, the output will be a relative blur one compared with the original.
\begin{figure}
\centering
\begin{subfigure}{0.4\textwidth}
  \centering
  \includegraphics[scale=0.5]{MSEref.png}
  \caption{ref}
\end{subfigure}
\begin{subfigure}{0.4\textwidth}
  \centering
  \includegraphics[scale=0.5]{MSEblur.png}
  \caption{MSE output}
\end{subfigure}
\end{figure}

\section{Learning Similarity Metrics for Numerical Simulations}

LSiM \cite{kohl2020learning} is a neural network-based approach that computes a stable and generalizing metric. Due to the unreliability of the MSE loss in numerical simulation tasks, LSiM has been established. It aims to demonstrate the performance of CNN-based evaluations on numerical simulation tasks. The data used to train LSiM are generated with known partial differential equations (PDEs). 

With figure 3.2, we can tell that the $L^2$ loss function consider plume b a closer image to the reference, while the fact is that plume a has a smaller distance to the reference image, which is exactly predicted by the LSiM.

\begin{figure}
\centering
\includegraphics[width=1.0\textwidth]{Plumes.pdf}
\caption{The loss computed between two different plume images and the reference with LSiM and $L^2$ metrics. While the GT is the ground truth distance determined by the data generation.  }
\end{figure}
The LSiM itself is also a CNN-based metric, see figure 3.3. The input of the network must be two batches of images with 3 channels
\begin{figure}
\centering
\includegraphics[width=1.0\textwidth]{DistanceComputation.pdf}
\caption{The Network structure of LSiM}
\end{figure}

As a metric, it also holds the metric properties $\forall \vx,\vy,\vz \in \sI$:
\begin{align}
    m(\vx,\vy) \; &\geq \; 0                && \text{non-negativity} \label{eq: NonNeg}\\
    m(\vx,\vy) \; &= \; m(\vy,\vx)              && \text{symmetry} \label{eq: Sym}\\
    m(\vx,\vy) \; &\leq \; m(\vx,\vz) + m(\vz,\vy)  && \text{triangle ineq.} \label{eq: TriIneq}\\
    m(\vx,\vy) \; &= 0 \; \iff \; \vx = \vy     && \text{identity of indisc.} \label{eq: IoI}
\end{align}

\section{VGG-16 loss network}

VGG-16\cite{simonyan2014very} is originally a CNN-based network trained for image classification problems. The author proposed 6 versions of vgg networks with different numbers of CNN layers but applied 3 fully connected layers for all of them at the end to realize the classification functionality. We adopted in the paper only the pretrained vgg-16 network(see figure 3.4) and apply it as a perceptual loss function.This pretrained model achieves 92.7\% top-5 test accuracy in ILSVRC-2014, which is challenge based on a dataset of over 14 million images belonging to 1000 classes. Although the networks was not originally trained for computing the distance, we can still use transfer learning to use it as a perceptual loss. In the paper\cite{johnson2016perceptual}, they chose to extract the third intermediate layer outputs and compute the MSE loss between them to realize the perceptual loss functionality(shown in figure 3.5)
\begin{figure}
\centering
\includegraphics[width=1.0\textwidth]{vgg16.png}
\caption{The network structure of vgg-16}
\end{figure}
\begin{figure}
\centering
\includegraphics[width=1.0\textwidth]{SystemFigure.pdf}
\caption{The system figure of their style transfer learning, we only focus on how they compute the loss function based on the vgg-16 network}
\end{figure}

Apartfrom that we have also tested extracting the first, second or the fourth intermediate layers to calculate the mse loss in order to compare the performance with the current method. We found out that computing mse between the third one has the best performance in our training task.

\section{Lpips}




%------- chapter 3 -------

\chapter{Datasets}
In this chapter we will cover the various dataset that we have adopted for training validation and testing in the following three tasks.

\section{Autoencoder}


\section{Superresolution}

\section{Solver in the Loop}
In the solver in the loop tasks, we have trained and tested out our model with 2 different fluid simulations, which are the 2-D karman flow and 2-D buoyancy driven flow. The author of the solver in the loop has mainly trained their model on the karmanflow, based on which we extend the model to a more complex simulation i.e. the buoyancy driven flow. For both simulation tasks, we have prepared two dataset with different resolutions in order to compare the performance of different loss functions on different resolutions. The two resolutions we chose for the Karmanflow are 128*64 and 64*32, and for buoyancy driven flow tasks we picked 64*64 and 128*128. As we want to reduce the numerical error for the model trained on a lower domain, for each resolution ratio we have to firstly generate a higher resolution dataset as the reference dataset, but we can not compare two datasets with different resolution therefore we have to downsample the higher resolution training set to a lower one that matches our training domain, and the downsampled dataset with rich simulation details from higher domain is our actual reference set.
As for the number of the simulations, we chose to generate 1500 frames for the karman flow and 250 frames for the buoyancy driven flow. Why we only chose 250 steps for the buoyancy driven flow is because we defined a closed boundary for the buoyancy flow so the simulation after 250 steps are extremely complex, and we also set the timestep to 0.1 to slow down the simulation so we will not have a chaotic frame of plumes.
For the test set we can alter the renolds number and the seed of the simulation to generate a sets of simulation frames that are overall similar but in details deviated from the used training set. 

\begin{figure}
\centering
\begin{subfigure}{0.4\textwidth}
  \centering
  \includegraphics[scale=0.5]{karmanflow.png}
  \caption{Karmanflow example}
\end{subfigure}
\begin{subfigure}{0.4\textwidth}
  \centering
  \includegraphics[scale=0.5]{buoyancy.png}
  \caption{Buoyancy driven flow example}
\end{subfigure}
\caption{Two simulation examples for Solver in the Loop}
\end{figure}

\begin{figure}
\centering
\begin{subfigure}{0.4\textwidth}
  \centering
  \includegraphics[scale=0.5]{buoyancy_high.png}
  \caption{Buoyancy driven flow image with 256*256}
\end{subfigure}
\begin{subfigure}{0.4\textwidth}
  \centering
  \includegraphics[scale=0.5]{buoyancy_ds.png}
  \caption{Downsampled buoyancy driven flow image with 128*128}
\end{subfigure}
\caption{Reference images generation and downsampling}
\end{figure}

The tool we used to perform the fluid simulation is Phiflow\cite{holl2020learning}





%------- chapter 4 -------

\chapter{Tasks and Experiments Setup}

\section{Autoencoder}

\section{Superresolution}

\section{Solver in the Loop}
\subsection{Karman flow}



%------- chapter 5 -------

\chapter{Results and Analysis}

\section{Comparison}

\subsection{Numerical evaluation}

\subsection{Time cost evaluation}

\section{Limitaions}





%------- chapter 6 -------

\chapter{Conclusion}
\section{Future work}
\section{Summary}






\appendix

\chapter{e.g. Questionnaire}

\textit{Note: If you have large models, additional evaluation data like questionnaires or non summarized results, put them into the appendix.}


\clearpage

\listoffigures
\clearpage

\listoftables
\clearpage

\bibliography{thesis}
\bibliographystyle{alpha}

\end{document}ison
