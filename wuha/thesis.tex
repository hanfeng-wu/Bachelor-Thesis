\documentclass[a4paper,12pt,twoside]{report}
\input{math_commands.tex} % math commands from https://github.com/goodfeli/dlbook_notation
\usepackage{acronym}
\usepackage{url}
\usepackage{cite}
\usepackage{listings}
\usepackage[pdftex]{graphicx}
\usepackage[hang,small,bf]{caption}
\usepackage{styles/tum}
\usepackage{setspace}
\usepackage[german,english]{babel}
\usepackage{float}
\usepackage{floatflt}
\usepackage{fancyhdr}
\usepackage{color}
\usepackage{booktabs}
\usepackage[pdftex,bookmarks=true,plainpages=false,pdfpagelabels=true]{hyperref}	%TODO make yourself familiar with \label, \ref and \hyperref for referencing figures, tables, chapters, etc.
\usepackage{mdwlist}
\usepackage{enumerate}
\usepackage{array}
\usepackage{longtable}
\usepackage[utf8]{inputenc}
\usepackage{wasysym}
\usepackage[capitalize, noabbrev]{cleveref}

\usepackage[numbers]{natbib}

\usepackage{svg}
\usepackage{amsmath}

\usepackage{subcaption}

\usepackage{algorithm, algorithmic}%

% Path for graphics
\graphicspath{{figures/}}

\begin{document}
\setlength{\evensidemargin}{22pt}
\setlength{\oddsidemargin}{22pt}

\def\doctype{Bachelor's Thesis}
\def\faculty{Informatik}
\def\title{Perceptual Losses for Deep Learning on Fluid Simulations}		%TODO add title in English
\def\titleGer{Perceptual Losses für Deep Learning von Flüssigkeitssimulationen}	%TODO add title in German
\def\supervisor{Prof.\ Dr.\  Nils Thürey}
\def\advisor{M.Sc.\ Georg Kohl}
\def\author{Hanfeng Wu}			%TODO add author name
\def\date{15.09.2021}		%TODO add submission / handover date


\hypersetup{pdfborder={0 0 0},
                        pdfauthor={<author>},
                        pdftitle={thesis-ba-hanfeng},
                        }

\lstset{showspaces=false, numbers=left, frame=single, basicstyle=\small}

\pagenumbering{alph}

\include{pages/cover}
\include{pages/titlepage}
\newpage
\thispagestyle{empty}
\mbox{}
\include{pages/disclaimer}		%TODO choose one of 'diploma | bachelor's | master's thesis' in the disclaimer file

\newpage
\thispagestyle{empty}
\mbox{}

\chapter*{Acknowledgements}


\pagenumbering{roman}

\selectlanguage{english}
\begin{abstract}

%abstract english

This thesis studies the integration of perceptual losses into several methods or approaches that are related to fluid simulation. Perceptual losses are used to compare high level differences, while traditional loss functions can only compute pixel-level differences reliably. 

First, some general concepts of fluid simulations, deep learning are discussed. Afterwards previous work on perceptual losses is discussed, which mainly focuses on image-related tasks like \cite{johnson2016perceptual, amirshahi2016, berardino2017, bosse2016, kang2014, kim2017}. Next, common methods for data comparison, which is an essential aspect of every perceptual loss function, are compared and characteristics highlighted. Next, we explain in detail several tasks we focus on such as Solver in the Loop and super-resolution. Then, in the experiments we integrate perceptual losses into these tasks in order to show that in the context of fluid simulation, the integration of some pretrained perceptual losses should outperform the traditional loss functions.

Eventually we combine the results of Solver in the Loop and super-resolution models together to achieve a lower time cost comparing to running a traditional fluid simulation.

\end{abstract}

\clearpage

\selectlanguage{german}
\begin{abstract}

Diese Dissertation untersucht die Integration von Wahrnehmungsverlusten in verschiedene Modelle, die sich auf die Fluidsimulation beziehen. Wahrnehmungsverluste werden verwendet, um Unterschiede auf hohem Niveau zu vergleichen, während herkömmliche Verlustfunktionen wie MSE und MAE nur die Pixelniveauunterschiede vergleichen, was roher ist.

Einige berühmte Wahrnehmungsverlustfunktionen wie der Vergleich der Zwischenschichten eines vortrainierten VGG-Netzwerks verbessern bereits seine Leistung bei einigen bildbezogenen Aufgaben.\cite{johnson2016perceptual} Wir wollen zeigen, dass die Integration einiger vortrainierter Wahrnehmungsverluste im Kontext der Fluidsimulation übertreffen auch die traditionellen Verlustfunktionen.

Wir haben einige Fluidsimulationsaufgaben in SOL\cite{um2020sol} getestet, um die Leistung der Percetual Loss Functions zu verbessern. Inzwischen integrieren wir solche Verlustfunktionen auch in Modelle wie Autoencoder und Superresolution, um deren Ergebnisse mit denen aus den gleichen Modellen zu vergleichen, die jedoch mit MSE-Verlustfunktionen trainiert wurden

Schließlich haben wir die Ergebnisse von SOL und Superauflösungsmodell kombiniert, um einige Fluidsimulationen zu geringeren Kosten durchzuführen, um den Vorteil der Integration von Wahrnehmungsverlusten in solchen Aufgaben zu zeigen.
%abstract german
\textit{Note: Insert the German translation of the English abstract here.}

\end{abstract}

\clearpage

\selectlanguage{english}


\tableofcontents
\clearpage

\clearpage

%\begin{acronym}
%\acro{SOL}{Solver in the Loop}
%\acro{LSIM}{Learning Similarity Metrics for Numerical Simulations}

%\end{acronym}

\pagenumbering{arabic}

\fancyhead{}
\pagestyle{fancy}
\fancyhead[LE]{\slshape \leftmark}
\fancyhead[RO]{\slshape \rightmark}
\headheight=15pt




%------- chapter 1 -------

\chapter{Introductions}

Our main purpose of this thesis is to demonstrate the advantage of adopting the perceptual loss functions in various deep learning tasks on fluid simulation. We try to show quantitatively and qualitatively that by integrating suitable perceptual loss functions in such tasks can outperform the original model trained on traditional loss functions such as MSE and MAE.  First we want to give a brief introduction to the core concepts of fluid simulation and their related tasks with deep learning techniques.
\section{Fluid simulation}
\subsection{Navier Stokes Equation}
The state-of-the-art fluid simulation is based on the famous incompressible equation Navier-Stokes equations

\begin{equation}
\frac{\partial \vec u}{\partial t}+\vec u\cdot \nabla\vec u+\frac1\rho\nabla p = \vec g + \nu\nabla\cdot\nabla\vec{u}
\end{equation}

\begin{equation}
{\nabla}\cdot\vec{u} = 0
\end{equation}

where $\nabla$ denotes the gradient, $\nabla\cdot$ denotes the Divergence, $\vec{u}$ denotes the velocity of the fluid, $t$ denotes the time step, $\rho$ denotes the density of the fluid, $p$ denotes the pressure, $\vec{g}$ denotes the gravity and $\nu$ denotes the viscosity of the fluid.

The equation (1.1) is actually a transformation of the $\vec{F} = m\vec{a}$ and the equation (1.2) describes the incompressibility of the fluid. There are two ways to regard the fluid in the simulation, which are Lagrangian point of view and Eulerian point of  view. Lagrangian point view focuses on the behavior of the fluid parcels, while Eulerian point of view focuses on the velocity fields, pressure fields that vary in time and space. We prefer to use Lagrangian point of view because the existing NS-equations focus more on the physical properties of the fluid parcel rather than describing the mathematical properties of the field.  In order to adopt the Lagrangian point of view, we need a grid structure to store the properties of our fluid parcels.

\subsection{Grid Stucture}
The way of storing the velocity and the density is based on two different grid structure. We store the density in the center of each cell, we call it centeredgrid or scalar grid. However for storing the velocity, we sample them at the face centers of each cell\cite{doi:10.1063/1.1761178}, while the pressure is stored in the center of each grid. In such way we can more easily compute the inflow and outflow of each grid for each direction. As a trade off for such grid structure, the data format would be more complex than normal centeredgrid. We usually have to stack each velocity array of each dimension together and also adopt them individually in some computations(e.g. computing loss function in deep learning)

\begin{figure}[h]
\centering
\includegraphics[width=\textwidth]{Staggered.png}
\caption{Staggered grid format \cite{staggeredform}}
\end{figure}

\subsection{Advection}
\begin{algorithm}\captionsetup{labelfont={sc,bf}, labelsep=newline}
	\caption{Incompressible fluid simulation algorithm}
\begin{algorithmic}
	\STATE {${\nabla}\cdot\vec{u} \gets 0$ (start with an initial velocity field $\vec{u}^{0}$ with the property)}
	\STATE {choose a time step $\Delta t$}
	\FOR {$n \gets 0, 1, 2, ...$}
	\STATE $\vec{u}^{A} \gets advect(\vec{u}^{n}, \vec{u}^{n}, \Delta t)$
	\STATE add the extra force $\vec{u}^{B} \gets \vec{u}^{A} + \Delta t\vec{g}$
	\STATE $\vec{u}^{n+1} \gets make\_incompressible(\Delta t, \vec{u}^{B})$
	\ENDFOR
\end{algorithmic}
\end{algorithm}

With the knowledge base of the NS-equation and grid structures we now need the advection algorithm to run the simulation. We adopt the semi-lagrangian advection algorithm. In the lagrangian point of view, if we want to compute the grid value of the n+1 time step of grid position $\vec{x_G}$, we should figure out which particle actually flows to the grid $\vec{x_G}$ from time step n+1. If we name the grid position of the particle as $\vec{x_P}$, then the new particle at time step n+1 in $\vec{x_G}$ should have the same physical property as the particle at time step n in $\vec{x_P}$

\begin{figure}[h]
\centering
\includegraphics[scale=0.5]{advection.png}
\caption{advection\cite{semi}}
\end{figure}

we first use the euler equation to calculate the $\vec{x_P}$ as a step before of $\vec{x_G}$
\begin{equation}
\vec x_P=\vec x_G-\Delta t\frac{d\vec x_G}{dt}
\end{equation}

because $\frac{d\vec x}{dt}=\vec u(\vec x)$ we have

\begin{equation}
\vec x_P=\vec x_G-\Delta t\vec u(\vec x_G)
\end{equation}
where $\vec u(\vec x_G)$ denotes the velocity sampled at the position $x_G$, with the advection we can update the velocity, pressure and density of the whole vector field.

with all the knowledge above, we can formulate a sequence to conduct the basic fluid simulation.(see Algorithm 1)


\section{Deep learning tasks}
In this section, we introduce several fluid simulation related tasks that we focus on in this thesis, and we explain how the deep learning techniques are integrated.
\subsection{Autoencoder}
The Autoencoder model has a bottle neck shape, which aims to produce the same output as the input. Once trained, the Autoencoder model can be separated into two parts, namely the encoder and the decoder, which can compress the image with the encoder and later decompress the image with the decoder to its former shape.
\subsection{Super-resolution}
With the super-resolution model, we can upscale the low-resolution images to high-resolution images. The model is able to super-resolute fluid simulation images if we feed similar data to train the model. In this paper, we apply the super-resolution model at the end of the Solver in the Loop model in order to boost the fluid simulation. Meanwhile, the simulation still obtain a similar output to the traditional simulation.
\subsection{Solver in the Loop}
When we want to perform our fluid simulation on a lower-resolution domain to decrease the time cost, we always suffer from the numerical error comparing to the simulation running on the higher-resolution domain. It is reasonable because with the same initial state, the vector field on the higher domain has richer information than the one sampled in the lower domain. \citeauthor{um2020sol} developed a mechanisim to learn the difference between the 2 different domains to reduce the numerical error.  We use the simulation from a high-resolution domain as the ground truth and make another same simulation with a lower resolution to approach our reference.  




\chapter{Related Work}
\paragraph{Perceptual losses related}The idea of jumping out of the traditional metrics based on $L^p$ norm has firstly begun by \cite{wang2004}, who developed the structure similarity index. Yet it was still not a perceptual loss and can not extract any deep features of the images. This situation has changed  until the discovery of CNN. Because CNNs are able to extract a lot of deep features structures and patterns from the image datasets (for example in 2014 \cite{simonyan2014very} has proposed the VGG structure which achieve a very good score on the ImageNet challenge), therefore more and more  works tend to use perceptual loss to evaluate their models\cite{amirshahi2016, berardino2017, bosse2016, kang2014, kim2017}. In 2016 \cite{johnson2016perceptual} used intermediate layer comparison from the trained VGG-16 network to evaluate their model for both super-resolution task and style-transfer task.  in 2018 \cite{zhang2018perceptual} developed a new approach to compute the perceptual loss function based on the trained deep CNNs, which, shown in his title, achieved unreasonable effectiveness. In 2020 \cite{kohl2020learning} proposed a new perceptual metric which focused on the numerical evaluation data.

The PDE model of adopting NS-equation in fluid simulation has firstly been brought up by \cite{doi:10.1063/1.1761178} in 1965. Then PDE models with machine learning started to be popular \cite{crutchfield1987equations,kevrekidis2003equation,brunton2016discovering}. More recently deep learning starting to play an important role in fluid dynamics \cite{kutz2017}. In 2019, \citeauthor{barsinai2019data} successfully integrate deep learning method into advection-diffusion problems to infer stencils. With the development of Phiflow \cite{holl2020learning}, Beside performing physical simulations, we are able to integrate different deep learning backends (Tensorflow and Pytorch), so that we can track the gradient of the vectors that are stored in different grid formats. With the help of Phiflow, \cite{um2020sol} used phiflow based deep learning methods to reduce the numerical error when performing fluid simulations. In 2020 \citeauthor{kim2020lagrangian} developed a neural style transfer approach from images to 3D fluids formulated in a Lagrangian viewpoint. Instead of using grid-based structure, \citeauthor{kim2020lagrangian} used particles for style transfer, which significantly reduce the training time.



%------- chapter 2 -------

\chapter{Metrics and Perceptual Losses}
Perceptual loss functions are used when comparing two images, they are not like traditional loss functions. For instance MSE or MAE only computes the low level pixel differences. Perceptual losses on the other hand, are normally forward networks trained for specific tasks. For example, VGG-16 network was trained for massive image classification, and LSIM was trained on smoke and fluid simulations. When adopting those networks, we can either compute the MSE loss between the intermediate layers of the trained network, or pass through the trained perceptual loss network depending on the original goal of the chosen network. These perceptual loss networks tries to retrieve the high level differences between the images, hence will usually have a better training performance than the traditional loss functions. In a word, perceptual losses can make the model achieve better training performance in specific tasks comparing to the traditional loss functions. 

In this thesis we mainly focus on comparing the performance between traditional loss function MSE and perceptual loss functions LSIM, VGG-16 and Lpips. In this chapter we will cover these loss functions that we adopted in this paper and briefly explain their characteristics and their drawbacks. More precise integration and results will be covered in the Chapter 5. 

\section{Mean Square Error}

MSE is one of the most widely used loss functions.
\begin{equation}
{MSE}=\frac{1}{n}\sum_{i=1}^n(Y_i-\hat{Y_i})^2
\end{equation}
Where ${Y}$ is the reference tensor and $\hat{Y}$ is the predicted tensor based on the trainable parameters of the model. The optimal case is that the predicted tensor $\hat{Y}$ is exactly the same as the reference tensor ${Y}$. We can see that the core idea for the MSE is very general so that this loss function can be applied almost for any models, however the MSE loss function is not suitable for some image related tasks. If the two inputs of the MSE loss function is merely a image with its core content shifted by some pixels, the MSE will produce a very high value, which is not representitive, in another word, the MSE does not have shift or rotate invariance. 

Besides, MSE computes the square error of the two tensors, which means that MSE is also prone to the outliers, beacause when it has a very large outlier in the tensor, the result of MSE loss function will be strongly influenced, so in most image construction cases, in order to achieve a lower square error, the output will be a relative blur one compared with the original. Because a sharper image means that the difference between pixel values is huge, which will result in the high square error. On contrary, a blur image means that the pixel values have smaller distance, which will more likely achieve a lower square error. When MSE being adopted, the loss function would rather have a blur area than having a sharp outlier.
\begin{figure}
\centering
\begin{subfigure}{0.4\textwidth}
  \centering
  \includegraphics[scale=0.5]{MSEref.png}
  \caption{ref}
\end{subfigure}
\begin{subfigure}{0.4\textwidth}
  \centering
  \includegraphics[scale=0.5]{MSEblur.png}
  \caption{MSE output}
\end{subfigure}
\end{figure}
 
\section{LSiM}

LSiM \cite{kohl2020learning} is a neural network-based approach that computes a stable and generalizing metric. Due to the unreliability of the MSE loss in numerical simulation tasks, LSiM has been established. It aims to demonstrate the performance of CNN-based evaluations on numerical simulation tasks. The data used to train LSiM are generated with known partial differential equations (PDEs). 

With figure 3.2, we can tell that the $L^2$ loss function consider plume b a closer image to the reference, while the fact is that plume a has a smaller distance to the reference image, which is exactly predicted by the LSiM. Notice that the so called ground truth in this case is determined by shifting some initial parameters of the simulation. If the initial parameters are more closer to those of the reference simulation, then the GT distance will be respectively smaller.

\begin{figure}
\centering
\includegraphics[width=1.0\textwidth]{Plumes.pdf}
\caption{The loss computed between two different plume images and the reference with LSiM and $L^2$ metrics. While the GT is the ground truth distance determined by the distance of the initial parameters in the data generation. }
\end{figure}
The LSiM itself is also a CNN-based metric, see figure 3.3. The input of the network must be two batches of images with 3 channels
\begin{figure}
\centering
\includegraphics[width=1.0\textwidth]{DistanceComputation.pdf}
\caption{The Network structure of LSiM}
\end{figure}

As a metric, it also holds the metric properties $\forall \vx,\vy,\vz \in \sI$:
\begin{align}
    m(\vx,\vy) \; &\geq \; 0                && \text{non-negativity} \label{eq: NonNeg}\\
    m(\vx,\vy) \; &= \; m(\vy,\vx)              && \text{symmetry} \label{eq: Sym}\\
    m(\vx,\vy) \; &\leq \; m(\vx,\vz) + m(\vz,\vy)  && \text{triangle ineq.} \label{eq: TriIneq}\\
    m(\vx,\vy) \; &= 0 \; \iff \; \vx = \vy     && \text{identity of indisc.} \label{eq: IoI}
\end{align}
In terms of application, LSiM is already itself a perceptual loss network.  According to \citeauthor{kohl2020learning}, we need to form a dictionary consisting of two image inputs. When we feed the dictionary into the LSiM network, the output will be the loss value.
\section{VGG-16 loss network}

VGG-16\cite{simonyan2014very} is originally a CNN-based network trained for image classification problems. The author proposed 6 versions of VGG networks with different numbers of CNN layers but applied 3 fully connected layers for all of them at the end to realize the classification functionality. We adopted in the paper only the pretrained VGG-16 network(see figure 3.4) and apply it as a perceptual loss function.This pretrained model achieves 92.7\% top-5 test accuracy in ILSVRC-2014, which is challenge based on a dataset of over 14 million images belonging to 1000 classes. Although the networks was not originally trained for computing the distance, we can still use transfer learning to use it as a perceptual loss. In the paper\cite{johnson2016perceptual}, they chose to extract the third intermediate layer outputs and compute the MSE loss between them to realize the perceptual loss functionality(shown in figure 3.5)
\begin{figure}
\centering
\includegraphics[width=1.0\textwidth]{vgg16.png}
\caption{The network structure of VGG-16}
\end{figure}
\begin{figure}
\centering
\includegraphics[width=1.0\textwidth]{SystemFigure.pdf}
\caption{How to extract the intermediate layer outputs of pretrained VGG-16 network to compute the loss.\cite{johnson2016perceptual}}
\end{figure}
Apart from that we have also tested extracting the first, second or the fourth intermediate layers to calculate the MSE loss in order to compare the performance with the current method. We found out that computing MSE between the third one has the best performance in our training task.

\section{Lpips}
Lpips as in Learned Perceptual Image Patch Similarity\cite{zhang2018perceptual} is also a trained network to compare the high level image features based on various distortions. According to the author, they adopted distortions like CNN-based distortions, superresolution, frame interpolation and so on for the dataset. Based on that, they use several psychophysical similarity measurements on the dataset, trying to approach the human judgements to the images. For the network architecture, they evaluate the SqueezeNet, AlexNet, and VGG architectures. Comparing with the vgg-16 loss function, we can consider Lpips as a advanced version of such method, because we do not only consider certain intermediate layer outputs, moreover we take advantage of more intermediate layer outputs and the perceptual judgement, which will be a more reliable comparison then just computing their mse difference.
\begin{figure}
\centering
\includegraphics[width=1.0\textwidth]{network_lpips.pdf}
\caption{The Lpips training setup: The distance is computed between the ground truth patch $x$ and the distorted patch $x_0$ or $x_1$ based on the chosen network architecture. The perceptual distance is then trained on a small network $G$. The ground truth of the model outputs is the Psychophysical Similarity Measurement $h$ , and the training is based on the Cross Entropy Loss\cite{zhang2018perceptual}}
\end{figure}
We in this project choose to use the AlexNet based Lpips.






%------- chapter 4 -------

\chapter{Datasets}
In this chapter we will cover the various datasets that we have adopted for training, validation and testing in the following three tasks.

\section{Autoencoder}
We set up the Autoencoder mainly to have a rough overview of the performance of the perceptual loss functions. Hence, we choose to use the nuerical simulation data with the original size of 256*256, on which the LSiM model was trained. 

Autoencoder can be trained without the supervision, because the training data is exactly the reference, so we do not need to do any modification to complete the training. However, in order to accelerate the training, we made 2 following modifications:
\begin{itemize}
\item since the numerical simulation data are mostly gray scale, which means we can sample them with one channel to boost our training and replicate the channel when certain loss functions demand their inputs in RBG channels. Such techniques can also be applied on any models with grayscale data, you can see more details about it in the Section 5.2.2.
\item in order to reduce the GPU usage, we downsample the 256*256 training data to the size of 128*128.

\end{itemize}


\section{Super-resolution}
The data we used in the superresolution task came from various sources. We first used the training data of LSiM model, because these are all numerical simulation data including the velocity, density and pressure images, so we recon that LSiM can outperform the other metrics.
\begin{figure}
\centering
\begin{subfigure}{0.3\textwidth}
  \centering
  \includegraphics[scale=0.5]{density.png}
  \caption{density data}
\end{subfigure}
\begin{subfigure}{0.3\textwidth}
  \centering
  \includegraphics[scale=0.5]{velocity.png}
  \caption{velocity data}
\end{subfigure}
\begin{subfigure}{0.3\textwidth}
  \centering
  \includegraphics[scale=0.5]{pressure.png}
  \caption{pressure data}
\end{subfigure}
\caption{Training set of LSiM model}
\end{figure}

We also want to test the performance of combining Solver in the loop and superresolution together to compete against the time cost with performing the simulation purely on the higher domain. Therefore we also feed the training data of the Solver in the Loop to the superresolution model, so that our model can learn to super sampling the plume density images when we feed the corrected simulation images on the lower domain. In this way, we are able to abtain the plume images with the same resolution as the higher domain.

Apart from that, we also test the our model performance on some random videos data which are not related to numerical simulations but still can be of some assistance to our model.
To create the data set, we form a dictionary for each image. We first downsample each training image $I_{high}$ to a lower resolution image $I_{downsampled}$(e.g. images of 256*256 to image of 64*64), then we resize the $I_{downsampled}$ to the same image size of the previous $I_{high}$, then we get a image $I_{low}$ with the same image size but a lower resolution as the $I_{high}$. In the training process we treat the $I_{low}$ as the input data of the model, $I_{high}$ as the groud truth to compute the loss with the model output.
\section{Solver in the Loop}
\subsection{Simulation tasks}
In the solver in the loop tasks, we have trained and tested out our model with 2 different fluid simulations, which are the 2-D karman flow and 2-D buoyancy driven flow. \citeauthor{um2020sol} has mainly trained their model on the karman flow, based on which we extend the model to a more complex simulation i.e. the buoyancy driven flow. 

For both simulation tasks, we have prepared two datasets with different resolutions in order to compare the performance of different loss functions on different resolutions. The two resolutions we chose for the karman flow are 128*64 and 64*32, and for buoyancy driven flow tasks we picked 64*64 and 128*128. As we want to reduce the numerical error for the model trained on a lower domain, for each resolution ratio we have to firstly generate a higher resolution dataset as the reference dataset. However, we can not compare two datasets with different resolutions. Therefore we have to down-sample the higher resolution training set to a lower one that matches our training domain. Afterwards, the down-sampled dataset with rich simulation details from higher domain is our actual reference set.

\begin{figure}
\centering
\begin{subfigure}{0.4\textwidth}
  \centering
  \includegraphics[scale=0.5]{karmanflow.png}
  \caption{Karmanflow example}
\end{subfigure}
\begin{subfigure}{0.4\textwidth}
  \centering
  \includegraphics[scale=0.5]{buoyancy.png}
  \caption{Buoyancy driven flow example}
\end{subfigure}
\caption{Two simulation examples for Solver in the Loop}
\end{figure}

\begin{figure}
\centering
\begin{subfigure}{0.4\textwidth}
  \centering
  \includegraphics[scale=0.5]{buoyancy_high.png}
  \caption{Buoyancy driven flow image with 256*256}
\end{subfigure}
\begin{subfigure}{0.4\textwidth}
  \centering
  \includegraphics[scale=0.5]{buoyancy_ds.png}
  \caption{Downsampled buoyancy driven flow image with 128*128}
\end{subfigure}
\caption{Reference images generation and downsampling}
\end{figure}
\subsection{Phiflow setup}
The tool we used to perform the fluid simulation is Phiflow\cite{holl2020learning}. 

For the karmanflow generation, we define an open domain with the size of 200(height) * 100(width). \textbf{(notice that domain size is not the same concept as the domain resolution. The domain size helps to locate the position of the inflow and obstacles of the simulation, while the resolution is used to define how percise we should sample our domain. Hence we could perform different resolution formats on the same domain size.)} we set the inflow as a 5 * 50 rectangle at the top center, and the obstacle as a circle with radius 10 positioned in the very center of the upper half of the domain. The step size $\Delta t$ we chose here is 1.0. For each simulation we chose to generate 1500 frames for the karman flow.

For the buoyancy driven flow generation, we define a 200 * 200 closed domain and set the inflow as a 5 * 100 rectangle at the bottom center. We generate 250 frames for each simulation. Why we only chose 250 steps for the buoyancy driven flow is because we defined a closed boundary for the buoyancy flow so the simulation after 250 steps are extremely complex, and we also set the timestep to 0.1 to slow down the simulation so we will not have a chaotic frame of plumes. Which helps to make our training easier.

For both tasks, we have a total of 8 simulations with their renolds numbers ranging from $1*10^5$ to $8*10^5$ as the training set. As for the test set we can alter the renolds number and the seed of the simulation to generate a sets of simulation frames that are overall similar but in details deviated from the used training set. 
\begin{figure}
	\centering
	\includegraphics[width=1.0\textwidth]{domaindescription.jpg}
	\caption{Domain set up of karman flow and buoyancy driven flow}
\end{figure}






%------- chapter 5 -------

\chapter{Tasks and Experiments Setup}

\section{Autoencoder}
\subsection{Network}
We used a very simple bottle-neck like and fully convolutional neural network for the Autoencoder(see figure 5.1). Due to the grey scale images, the input and output channel size is set to 1. We apply two convlution layers followed by one max pooling layer and two upsample convolution layer(i.e. the ConvTranspose2d layer). In order to keep the tensor value within a reasonable range, we add before the final output a 256*sigmoid layer to ensure that every output value should lie in between [0, 255]. However sigmoid should not be used in the intermediate layers, which will cause vanishing gradient problem, so we use ReLU as the activation function for the intermediate layer. The reason why we don not add a ReLU activation function before the sigmoid is because the ReLU only outputs positive values which wil results in that the sigmoid function will then only output values greater then 0.5, then we will lose half of the value range of the images which is not acceptable.
\subsection{Application of loss functions}
Before feeding the input image to the model and compute the loss function, we can still add on some modification to make our training eaiser. Since most of our data are smoke images or velocity fields, so they are in grey scale. In this case, we can modify our network in the way that the new input channel size and the output channel size are 1, because the grey scale images only have one channel. With this modification, our model does not need to learn to align all the three RBG channels to the same value, hence it will strongly reduce the training difficulty. However, in the process of applying the loss function, there will be the problem that many of the perceptual loss functions only accept RBG images that the input tensors should have three channels. In order to fix this, we choose to replicate the channel size to three with the same values, so the loss functions will regard our grey scale images as RBG images. In this way we keep the tensors in the training process as one-channel tensors however in the loss function computation process as three-channels tensors, which increase our model performance.

In order to compute the loss functions, we need to define the reference and the model output. Now we know our first input is the model output with replicated channels, and the reference input should be the $I_{high}$. The rest is to define the respective metrics. For MSE loss we can directly compute it between two tensors. For vgg-16 loss functions, we can feed each tensor into the model and compute MSE loss between their third intermediate outputs. For LSiM we can form a dictionary of these two tensors and pass it to the forward function of the LSiM model. For Lpips we can directly use the pretrained model and feed the two tensors into the function.


\begin{figure}
  \centering
  \includegraphics[width=\textwidth]{autoencoder.png}
  \caption{The structure of Autoencoder}
\end{figure}

\section{Superresolution}
\begin{figure}
	\centering
	\includegraphics[scale=0.5]{ITN.png}
	\caption{The structure of ImageTranformationNetwork of \cite{johnson2016perceptual}}
\end{figure}
\subsection{Network}
We adopt the same ImageTranformNetwork proposed by \citeauthor{johnson2016perceptual}, which is a fully convolutional network that has the same output tensor as the input. The network consists of three Convlayers, three UpsampleConvlayers and five residual blocks.(Notice that we do not use the deconvolutional layer in the UpsampleConvlayers as suggested in the paper\cite{odena2016deconvolution}, that deconvolutional layers will likely result into checkerboards artifacts due to the overlapping when doing the reverse convolution operations. So we prefer to fistly do the traditional upsampling either with Nearest-neighbor interpolation or with Bilinear interpolation then we apply the convlayer afterwards to obtain the expected upsampled size.)
\begin{figure}
\centering
\begin{subfigure}{0.49\textwidth}
  \centering
  \includegraphics[scale=0.6]{style_artifacts.png}
  \caption{Using deconvolution. Heavy checkerboard artifacts.}
\end{subfigure}
\begin{subfigure}{0.49\textwidth}
  \centering
  \includegraphics[scale=0.6]{style_clean.png}
  \caption{Using resize-convolution. No checkerboard artifacts.}
\end{subfigure}
\caption{The comparison between two upsample methods\cite{odena2016deconvolution}}
\end{figure}

Since the outputs of our model is RBG images, which means the tensor values lie in the range of [0, 255], so we apply at the end of the last upsampling layer a sigmoid function and times 256. In such way, we can ensure that our output tensor value won't exceed the range. Since the input tensor and the output tensor share the same shape, so before we feed the low resolution data to the model, we need to first do the upsampling with some interpolation methods(we choose bilinear here) to resize our input images to the expected high resolution, then feed them to the model. 

\subsection{Applying loss functions}
The training process of super-resolution is very similar to that in the autoencoder task. The only different part is that we in the autoencoder use the same training data as the reference data, however in the super-resolution we use the downresoluted images as the training data. In terms of applying loss function, we also need to replicate the channels to suit the input shape of certain loss functions. For more details of how to deploy such modification, please turn to the Section 5.1.2


\section{Solver in the Loop}
After we have generated the training set and its down-sampled version, we can start the training. We will first cover the basics of the network and its training goal, then we will go into details of how to apply the loss function.
\subsection{Network}
The training network we used is called MarsMoon, which is the same network that \cite{um2020sol} adopted in the his project(see figure 5.4) we can see that the number of channels for both input and output is 2. This is because the input is the staggered tensor of the velocity which has two directions one represents the y direction and the other represents the x direction. The output of the network is also a staggered tensor however it can not be directly addressed as the velocity but a correction of the velocity, which can be added to the velocity calculated on the lower domain, then the corrected velocity can be applied for the next simulation step. The reason why we do not train the output towards the velocity for the next simulation step is because we want to take advantage of the physical information stored in those tensors, if we should simply get the next velocity from passing the former velocity through the network, then we would not need to perform the physical simulation, which is very unstable. Thus, adding the trained correction to the physical simulation output of the former velocity would at least make sure that our simulation is performing on the right track. That means our consecutive steps of the simulation are based on valid physical simulation, which can not be ensured by purely passing through the neural network.
\begin{figure}
\centering
\includegraphics[width=1.0\textwidth]{marsmoon.jpg}
\caption{The network architecture\cite{um2020sol}}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=1.0\textwidth]{Manifolds.pdf}
\caption{The training goal is to obtain the suitable correction, with which the simulation on the lower domain can reduce the numerical error. The brown one represents the source simulation of the lower domain without any corrections, the blue one represents the simulation on the higher domain which is our target, the green one is the brown one plus the trained correction, which aims to approach the blue one\cite{um2020sol}}
\end{figure}
\subsection{Training Set}
In karman flow simulation, we choose not to use the whole training set to train our model, as in the first several steps of karman flow do not have much difference between high and low domains. So we only try to train the last 1000 steps of the total 1500 steps. When we train the lower domain 64*32 karman flow, we also find out that the 64*32 image for LSiM model is too small, so we decide to alter the domain to the resolution of 64*64, correspondingly the training set also need to be retrained on the domain of 128*128. However the size of the plume remains unchanged, we only pad the domain such that they can be applied to LSiM loss function.(see figure 5.6)
\begin{figure}
\centering
\begin{subfigure}{0.4\textwidth}
  \centering
  \includegraphics[scale=1]{nonpad_karmanflow.png}
  \caption{}
\end{subfigure}
\begin{subfigure}{0.4\textwidth}
  \centering
  \includegraphics[scale=1]{pad_karmanflow.png}
  \caption{}
\end{subfigure}
\caption{Padding plume image to match the input size of LSiM model}
\end{figure}
For the buoyancy driven flow simulation, it only consists of 250 steps and each step has rich numerical information, so we regard the whole simulation as the training set. Besides, since the buoyancy simulation on the lower domain already has the shape of 64*64 we don't need to add extra padding to suit the LSiM model.


\subsection{Applying loss functions}
In order to compute the loss we have to define the 2 inputs of our loss functions. We know our model output is the correction, however it is unreasonable to directly compare the correction with the reference simulation. So the two inputs of the loss functions should be 
\begin{itemize}
\item $V$: The sum between the velocity tensor on the lower-domain simulation and our trained correction .

\item $\hat{V}$: The down-sampled velocity tensor from the higher-domain simulation(reference).
\end{itemize}


For the MSE loss, which is exactly used by \citeauthor{um2020sol} in his project, we can simply calculate their pixel wise square difference and compute their mean. This traditional loss function does not rely on the structure of the tensor as long as they share the same shape. So the MSE loss between two staggered tensors can be easily computed. However the perceptual loss function has some demands on our tensor shape due to its CNN structure. For example, LSiM requires that the input tensor should consist of 3 channels to represent the RBG channels, while the size of the input tensor should be large enough to pass through several conv-layers. In our case, the output of the model is a staggered tensor with 2 channels which respectively represent x and y directions. Our solution is, that we compute the loss over each direction separately and sum them up. We firstly both extract the x direction tensor $V_x$ and y direction tensor $V_y$ from our model output $V$, then we also extract the x direction tensor $\hat{V_x}$ and y direction tensor $\hat{V_y}$ from the reference velocity tensor $\hat{V}$. Our final loss function representation looks like:
\begin{equation}
 Loss(V, \hat{V}) = F(V_x, \hat{V_x}) + F(V_y, \hat{V_y})
\end{equation}
where F is the respective perceptual loss function. In this way, we are able to treat the velocity tensor on each direction as an image(or triplicate the channel to RBG image) and compare them with their ground truth.  






%------- chapter 5 -------

\chapter{Results and Analysis}

\section{Comparison}
\subsection{Autoencoder}

\begin{figure}
	\centering
	\begin{subfigure}{0.19\textwidth}
		\centering
		\includegraphics[scale=0.29]{autoencoder/ref1.png}
		\caption{$Reference$}
	\end{subfigure}
	\begin{subfigure}{0.19\textwidth}
		\centering
		\includegraphics[scale=0.29]{autoencoder/mse1.png}
		\caption{$MSE$}
	\end{subfigure}
	\begin{subfigure}{0.19\textwidth}
		\centering
		\includegraphics[scale=0.29]{autoencoder/lsim1.png}
		\caption{$LSiM$}
	\end{subfigure}
	\begin{subfigure}{0.19\textwidth}
		\centering
		\includegraphics[scale=0.29]{autoencoder/lpips1.png}
		\caption{$Lpips$}
	\end{subfigure}
	\begin{subfigure}{0.19\textwidth}
		\centering
		\includegraphics[scale=0.29]{autoencoder/vgg1.png}
		\caption{$VGG-16$}
	\end{subfigure}
	\caption{Pressure images}
\end{figure}


\begin{figure}
	\centering
	\begin{subfigure}{0.19\textwidth}
		\centering
		\includegraphics[scale=0.29]{autoencoder/ref2.png}
		\caption{$Reference$}
	\end{subfigure}
	\begin{subfigure}{0.19\textwidth}
		\centering
		\includegraphics[scale=0.29]{autoencoder/mse2.png}
		\caption{$MSE$}
	\end{subfigure}
	\begin{subfigure}{0.19\textwidth}
		\centering
		\includegraphics[scale=0.29]{autoencoder/lsim2.png}
		\caption{$LSiM$}
	\end{subfigure}
	\begin{subfigure}{0.19\textwidth}
		\centering
		\includegraphics[scale=0.29]{autoencoder/lpips2.png}
		\caption{$Lpips$}
	\end{subfigure}
	\begin{subfigure}{0.19\textwidth}
		\centering
		\includegraphics[scale=0.29]{autoencoder/vgg2.png}
		\caption{$VGG-16$}
	\end{subfigure}
	\caption{Density images}
\end{figure}
 \begin{figure}
	\centering
	\begin{subfigure}{0.32\textwidth}
		\centering
		\includegraphics[scale=0.5]{autoencoder/l2eval.png}
		\caption{L2 evaluation}
	\end{subfigure}
	\begin{subfigure}{0.32\textwidth}
		\centering
		\includegraphics[scale=0.5]{autoencoder/l1eval.png}
		\caption{L1 evaluation}
	\end{subfigure}
	\begin{subfigure}{0.32\textwidth}
		\centering
		\includegraphics[scale=0.5]{autoencoder/mseeval.png}
		\caption{MSE evaluation}
	\end{subfigure}
	\begin{subfigure}{0.32\textwidth}
		\centering
		\includegraphics[scale=0.5]{autoencoder/lsimeval.png}
		\caption{LSiM evaluation}
	\end{subfigure}
	\begin{subfigure}{0.32\textwidth}
		\centering
		\includegraphics[scale=0.5]{autoencoder/ssimeval.png}
		\caption{SSIM evaluation}
	\end{subfigure}
	\begin{subfigure}{0.32\textwidth}
		\centering
		\includegraphics[scale=0.5]{autoencoder/lpipseval.png}
		\caption{Lpips evaluation}
	\end{subfigure}
	\caption{Numerical evaluation of each metrics on testset of autoencoder}
\end{figure}
We train the autoencoder model on density, pressure and velocity data of smokes, here are some examples of the training outputs. The reference image as well as the training input is on the left side  while the rest are different model outputs trained by their respective losses. We can see that for every output, there are some blur area on the sides. The reason might be that our autoencoder model is too simple so it does not provide enough feature extractors to extract and rebuild the features of the smoke images. MSE and LSiM in this case share similar performance, while Lpips provide a darker reconstruction than the others. The model trained by VGG-16 loss function has the best output. We can infer that from the rich information on the edges of the smoke images.

 Along with the images we provide the numerical evaluations for each loss. We pick L2, L1, LSiM, MSE, SSIM, Lpips as the methods to compute the numerical distance to the reference image. We compute the average of each metric over 1056 test smoke images. The evaluations agree to our intuition of the images. MSE and LSiM achieve the best score in the evaluation using their selves, while sharing the same score in the SSiM evaluation. Lpips presents the worst performance among the 4 metrics and VGG-16 achieves the best scores in both SSIM evaluation and Lpips evaluation.  
\subsection{Super-resolution}

\begin{figure}
	\centering
	\begin{subfigure}{0.32\textwidth}
		\centering
		\includegraphics[scale=0.4]{superresolution/density_low.png}
		\caption{$Downsampled$}
	\end{subfigure}
	\begin{subfigure}{0.32\textwidth}
		\centering
		\includegraphics[scale=0.4]{superresolution/density_ref.png}
		\caption{$Reference$}
	\end{subfigure}
	\begin{subfigure}{0.32\textwidth}
		\centering
		\includegraphics[scale=0.4]{superresolution/density_mse.png}
		\caption{$MSE$}
	\end{subfigure}
	\begin{subfigure}{0.32\textwidth}
		\centering
		\includegraphics[scale=0.4]{superresolution/density_lsim.png}
		\caption{$LSiM$}
	\end{subfigure}
	\begin{subfigure}{0.32\textwidth}
		\centering
		\includegraphics[scale=0.4]{superresolution/density_vgg.png}
		\caption{$VGG-16$}
	\end{subfigure}
	\begin{subfigure}{0.32\textwidth}
		\centering
		\includegraphics[scale=0.4]{superresolution/density_lpips.png}
		\caption{$Lpips$}
	\end{subfigure}
	\caption{Smoke density images:}
\end{figure}

\begin{figure}
	\centering
	\begin{subfigure}{0.32\textwidth}
		\centering
		\includegraphics[scale=0.4]{superresolution/pressure_low.png}
		\caption{$Downsampled$}
	\end{subfigure}
	\begin{subfigure}{0.32\textwidth}
		\centering
		\includegraphics[scale=0.4]{superresolution/pressure_ref.png}
		\caption{$Reference$}
	\end{subfigure}
	\begin{subfigure}{0.32\textwidth}
		\centering
		\includegraphics[scale=0.4]{superresolution/pressure_mse.png}
		\caption{$MSE$}
	\end{subfigure}
	\begin{subfigure}{0.32\textwidth}
		\centering
		\includegraphics[scale=0.4]{superresolution/pressure_lsim.png}
		\caption{$LSiM$}
	\end{subfigure}
	\begin{subfigure}{0.32\textwidth}
		\centering
		\includegraphics[scale=0.4]{superresolution/pressure_vgg.png}
		\caption{$VGG-16$}
	\end{subfigure}
	\begin{subfigure}{0.32\textwidth}
		\centering
		\includegraphics[scale=0.4]{superresolution/pressure_lpips.png}
		\caption{$Lpips$}
	\end{subfigure}
	\caption{Smoke Pressure images}
\end{figure}

\begin{figure}
	\centering
	\begin{subfigure}{0.32\textwidth}
		\centering
		\includegraphics[scale=0.4]{superresolution/liquidvel_low.png}
		\caption{$Downsampled$}
	\end{subfigure}
	\begin{subfigure}{0.32\textwidth}
		\centering
		\includegraphics[scale=0.4]{superresolution/liquidvel_ref.png}
		\caption{$Reference$}
	\end{subfigure}
	\begin{subfigure}{0.32\textwidth}
		\centering
		\includegraphics[scale=0.4]{superresolution/liquidvel_mse.png}
		\caption{$MSE$}
	\end{subfigure}
	\begin{subfigure}{0.32\textwidth}
		\centering
		\includegraphics[scale=0.4]{superresolution/liquidvel_lsim.png}
		\caption{$LSiM$}
	\end{subfigure}
	\begin{subfigure}{0.32\textwidth}
		\centering
		\includegraphics[scale=0.4]{superresolution/liquidvel_vgg.png}
		\caption{$VGG-16$}
	\end{subfigure}
	\begin{subfigure}{0.32\textwidth}
		\centering
		\includegraphics[scale=0.4]{superresolution/liquidvel_lpips.png}
		\caption{$Lpips$}
	\end{subfigure}
	\caption{Liquid velocity images}
\end{figure}

\begin{figure}
	\centering
	\begin{subfigure}{0.32\textwidth}
		\centering
		\includegraphics[scale=0.5]{superresolution/l2.png}
		\caption{L2 evaluation}
	\end{subfigure}
	\begin{subfigure}{0.32\textwidth}
		\centering
		\includegraphics[scale=0.5]{superresolution/l1.png}
		\caption{L1 evaluation}
	\end{subfigure}
	\begin{subfigure}{0.32\textwidth}
		\centering
		\includegraphics[scale=0.5]{superresolution/mse.png}
		\caption{MSE evaluation}
	\end{subfigure}
	\begin{subfigure}{0.32\textwidth}
		\centering
		\includegraphics[scale=0.5]{superresolution/lsim.png}
		\caption{LSiM evaluation}
	\end{subfigure}
	\begin{subfigure}{0.32\textwidth}
		\centering
		\includegraphics[scale=0.5]{superresolution/ssim.png}
		\caption{SSIM evaluation}
	\end{subfigure}
	\begin{subfigure}{0.32\textwidth}
		\centering
		\includegraphics[scale=0.5]{superresolution/lpips.png}
		\caption{Lpips evaluation}
	\end{subfigure}
	\caption{Numerical evaluation of each metrics on test set of the super-resolution task}
\end{figure}
We trained our ImageTransformNet based Super-resolution model on the data combined by smoke and liquid data. Both smoke and liquid data consist of density, velocity and pressure images. We sampled them all in gray scale hence only one channel.
We can see in terms of smoke density images, every other metrics have some artifacts within the plumes, while LSiM reconstructs the downsampled images well. This problem can be solved if we choose to train our model solely on the smoke density data. However the model will then lose its generality.
As for the liquid velocity images, we can see that MSE and VGG-16 metrics generate a more blur image compare to the LSiM and Lpips. Because VGG-16 also computes the MSE loss between the intermediate Layers, so these two metrics tend to achieve a blur image to reduce the loss value. The other two metrics LSiM and Lpips, on the other hand, tend to generate a sharper image to approach the reference. In this case, VGG-16 metric achieve the best performance.

We also run the numerical evaluation on all the models we trained. We use 6 metrics to compute the distance between each model outputs and the references. According to the charts, we can tell that Lpips has the worst performance over all metrics, which is similar to the result of the autoencoder task. The other three metrics share the similar results in L2 and SSIM evaluation. VGG-16 achieve the best score in LSiM evaluation, LSiM itself achieve the second best and MSE the third.


\begin{figure}
	\centering
	\begin{subfigure}{0.32\textwidth}
		\centering
		\includegraphics[scale=0.5]{superresolution/checkerboard_mse.png}
		\caption{MSE output}
	\end{subfigure}
	\begin{subfigure}{0.32\textwidth}
		\centering
		\includegraphics[scale=0.5]{superresolution/checkerboard_lsim.png}
		\caption{LSiM output}
	\end{subfigure}
	\begin{subfigure}{0.32\textwidth}
		\centering
		\includegraphics[scale=0.5]{superresolution/checkerboard_vgg.png}
		\caption{VGG-16 output}
	\end{subfigure}
	\begin{subfigure}{0.32\textwidth}
		\centering
		\includegraphics[scale=0.5]{superresolution/checkerboard_ref.png}
		\caption{Reference}
	\end{subfigure}
	\caption{Besides we have also tested the RGB channels model of ImageTransformNet on the density data. We can see when trained with LSiM metric, the output image has very obvious artifacts that tends to divide the images into 9 parts. This problem can be solved by sampling the images in gray scale and adopt the one channel ImageTransformNet model}
\end{figure}

We have also tested the karman flow data from Solver in the loop in the super-resolution model. 
\begin{figure}
	\centering
	\begin{subfigure}{0.32\textwidth}
		\centering
		\includegraphics[scale=0.5]{superresolution/karman_down.png}
		\caption{$Downsampled$}
	\end{subfigure}
	\begin{subfigure}{0.32\textwidth}
		\centering
		\includegraphics[scale=0.5]{superresolution/karman_ref.png}
		\caption{$Reference$}
	\end{subfigure}
	\begin{subfigure}{0.32\textwidth}
		\centering
		\includegraphics[scale=0.5]{superresolution/karman_mse.png}
		\caption{$MSE$}
	\end{subfigure}
	\begin{subfigure}{0.32\textwidth}
		\centering
		\includegraphics[scale=0.5]{superresolution/karman_lsim.png}
		\caption{$LSiM$}
	\end{subfigure}
	\begin{subfigure}{0.32\textwidth}
		\centering
		\includegraphics[scale=0.5]{superresolution/karman_vgg.png}
		\caption{$VGG-16$}
	\end{subfigure}
	\begin{subfigure}{0.32\textwidth}
		\centering
		\includegraphics[scale=0.5]{superresolution/karman_lpips.png}
		\caption{$Lpips$}
	\end{subfigure}
	\caption{karman flow images comparison}
\end{figure}
The numerical evaluation is quite surprising. Despite Lpips outputs have the closest color to the reference, it has the worst score over all the evaluations. LSiM achieve the best score in all evaluations. However intuitively, we can hardly tell the difference between the MSE, LSiM and VGG-16 outputs.
 
\begin{figure}
	\centering
	\begin{subfigure}{0.32\textwidth}
		\centering
		\includegraphics[scale=0.48]{superresolution/karman_eval_l2.png}
		\caption{L2 evaluation}
	\end{subfigure}
	\begin{subfigure}{0.32\textwidth}
		\centering
		\includegraphics[scale=0.48]{superresolution/karman_eval_l1.png}
		\caption{L1 evaluation}
	\end{subfigure}
	\begin{subfigure}{0.32\textwidth}
		\centering
		\includegraphics[scale=0.48]{superresolution/karman_eval_mse.png}
		\caption{MSE evaluation}
	\end{subfigure}
	\begin{subfigure}{0.32\textwidth}
		\centering
		\includegraphics[scale=0.48]{superresolution/karman_eval_lsim.png}
		\caption{LSiM evaluation}
	\end{subfigure}
	\begin{subfigure}{0.32\textwidth}
		\centering
		\includegraphics[scale=0.48]{superresolution/karman_eval_ssim.png}
		\caption{SSIM evaluation}
	\end{subfigure}
	\begin{subfigure}{0.32\textwidth}
		\centering
		\includegraphics[scale=0.48]{superresolution/karman_eval_lpips.png}
		\caption{Lpips evaluation}
	\end{subfigure}
	\caption{Numerical evaluation of each metrics on test set of the super-resolution task trained on karman flow data}
\end{figure}

\subsection{Solver in the loop}
After training lots of models on both buoyancy driven flow and the karman flow of different resolutions, we have following results. In terms of numerical evaluation, we compute the distance of various metrics(L1, L2, MSE, LSiM, SSIM, Lpips) between the simulation corrected by the models trained by different loss functions, and the down-sampled reference simulation. We compute the distance between each corresponding frames pair and compute their average as the result.
\begin{itemize}
  \item Karman flow
\end{itemize}
From the comparisons from the figures, we can see that the source simulation has deviated from the reference after 1000 steps. We have also trained in our models only the latter 500 images of the reference karman flow. Lpips obviously has the worst performance, the plume is shifting to the right and there are noticeable artifacts near the obstacle. MSE LSiM and VGG-16 share similar outputs after step 1000.

In our numerical evaluation, we only compare the the simulation frames after step 1000 with their reference frames. We didn't compare the whole 1500 steps because we believe that considering all steps is not suitable since the reference images of the training only come from the latter 500 simulation steps. In terms of L1, L2 and MSE comparisons, we can see all corrected models have better scores than the source simulation. In the other evaluations, LSiM achieved overall the best score, followed by the VGG-16. MSE is not better than the source simulation, which is deviated from \citeauthor{um2020sol}'s work. We think the deviation may come from that we didn't choose a large multi steps in the training and we didn't choose a large training epoch number. Still we prove that LSiM or VGG-16 outperform MSE in terms of this specific task.

\begin{figure}
	\centering
	\begin{subfigure}{0.18\textwidth}
		\centering
		\includegraphics[scale=0.5]{karmanflow/ref_density_000250.png}
		\caption{$t=250$}
	\end{subfigure}
	\begin{subfigure}{0.18\textwidth}
		\centering
		\includegraphics[scale=0.5]{karmanflow/ref_density_000500.png}
		\caption{$t=500$}
	\end{subfigure}
	\begin{subfigure}{0.18\textwidth}
		\centering
		\includegraphics[scale=0.5]{karmanflow/ref_density_001000.png}
		\caption{$t=1000$}
	\end{subfigure}
	\begin{subfigure}{0.18\textwidth}
		\centering
		\includegraphics[scale=0.5]{karmanflow/ref_density_001250.png}
		\caption{$t=1250$}
	\end{subfigure}
	\begin{subfigure}{0.18\textwidth}
		\centering
		\includegraphics[scale=0.5]{karmanflow/ref_density_001499.png}
		\caption{$t=1499$}
	\end{subfigure}
	\caption{Karman flow reference simulation}
\end{figure}

\begin{figure}
	\centering
	\begin{subfigure}{0.18\textwidth}
		\centering
		\includegraphics[scale=0.5]{karmanflow/source_density_000250.png}
		\caption{$t=250$}
	\end{subfigure}
	\begin{subfigure}{0.18\textwidth}
		\centering
		\includegraphics[scale=0.5]{karmanflow/source_density_000500.png}
		\caption{$t=500$}
	\end{subfigure}
	\begin{subfigure}{0.18\textwidth}
		\centering
		\includegraphics[scale=0.5]{karmanflow/source_density_001000.png}
		\caption{$t=1000$}
	\end{subfigure}
	\begin{subfigure}{0.18\textwidth}
		\centering
		\includegraphics[scale=0.5]{karmanflow/source_density_001250.png}
		\caption{$t=1250$}
	\end{subfigure}
	\begin{subfigure}{0.18\textwidth}
		\centering
		\includegraphics[scale=0.5]{karmanflow/source_density_001499.png}
		\caption{$t=1499$}
	\end{subfigure}
	\caption{Karman flow source simulation without correction}
\end{figure}

\begin{figure}
	\centering
	\begin{subfigure}{0.18\textwidth}
		\centering
		\includegraphics[scale=0.5]{karmanflow/mse_density_000250.png}
		\caption{$t=250$}
	\end{subfigure}
	\begin{subfigure}{0.18\textwidth}
		\centering
		\includegraphics[scale=0.5]{karmanflow/mse_density_000500.png}
		\caption{$t=500$}
	\end{subfigure}
	\begin{subfigure}{0.18\textwidth}
		\centering
		\includegraphics[scale=0.5]{karmanflow/mse_density_001000.png}
		\caption{$t=1000$}
	\end{subfigure}
	\begin{subfigure}{0.18\textwidth}
		\centering
		\includegraphics[scale=0.5]{karmanflow/mse_density_001250.png}
		\caption{$t=1250$}
	\end{subfigure}
	\begin{subfigure}{0.18\textwidth}
		\centering
		\includegraphics[scale=0.5]{karmanflow/mse_density_001499.png}
		\caption{$t=1499$}
	\end{subfigure}
	\caption{Karman flow simulation trained with MSE}
\end{figure}

\begin{figure}
	\centering
	\begin{subfigure}{0.18\textwidth}
		\centering
		\includegraphics[scale=0.5]{karmanflow/lsim_density_000250.png}
		\caption{$t=250$}
	\end{subfigure}
	\begin{subfigure}{0.18\textwidth}
		\centering
		\includegraphics[scale=0.5]{karmanflow/lsim_density_000500.png}
		\caption{$t=500$}
	\end{subfigure}
	\begin{subfigure}{0.18\textwidth}
		\centering
		\includegraphics[scale=0.5]{karmanflow/lsim_density_001000.png}
		\caption{$t=1000$}
	\end{subfigure}
	\begin{subfigure}{0.18\textwidth}
		\centering
		\includegraphics[scale=0.5]{karmanflow/lsim_density_001250.png}
		\caption{$t=1250$}
	\end{subfigure}
	\begin{subfigure}{0.18\textwidth}
		\centering
		\includegraphics[scale=0.5]{karmanflow/lsim_density_001499.png}
		\caption{$t=1499$}
	\end{subfigure}
	\caption{Karman flow simulation trained with LSiM}
\end{figure}

\begin{figure}
	\centering
	\begin{subfigure}{0.18\textwidth}
		\centering
		\includegraphics[scale=0.5]{karmanflow/lpips_density_000250.png}
		\caption{$t=250$}
	\end{subfigure}
	\begin{subfigure}{0.18\textwidth}
		\centering
		\includegraphics[scale=0.5]{karmanflow/lpips_density_000500.png}
		\caption{$t=500$}
	\end{subfigure}
	\begin{subfigure}{0.18\textwidth}
		\centering
		\includegraphics[scale=0.5]{karmanflow/lpips_density_001000.png}
		\caption{$t=1000$}
	\end{subfigure}
	\begin{subfigure}{0.18\textwidth}
		\centering
		\includegraphics[scale=0.5]{karmanflow/lpips_density_001250.png}
		\caption{$t=1250$}
	\end{subfigure}
	\begin{subfigure}{0.18\textwidth}
		\centering
		\includegraphics[scale=0.5]{karmanflow/lpips_density_001499.png}
		\caption{$t=1499$}
	\end{subfigure}
	\caption{Karman flow simulation with Lpips}
\end{figure}

\begin{figure}
	\centering
	\begin{subfigure}{0.18\textwidth}
		\centering
		\includegraphics[scale=0.5]{karmanflow/vgg_density_000250.png}
		\caption{$t=250$}
	\end{subfigure}
	\begin{subfigure}{0.18\textwidth}
		\centering
		\includegraphics[scale=0.5]{karmanflow/vgg_density_000500.png}
		\caption{$t=500$}
	\end{subfigure}
	\begin{subfigure}{0.18\textwidth}
		\centering
		\includegraphics[scale=0.5]{karmanflow/vgg_density_001000.png}
		\caption{$t=1000$}
	\end{subfigure}
	\begin{subfigure}{0.18\textwidth}
		\centering
		\includegraphics[scale=0.5]{karmanflow/vgg_density_001250.png}
		\caption{$t=1250$}
	\end{subfigure}
	\begin{subfigure}{0.18\textwidth}
		\centering
		\includegraphics[scale=0.5]{karmanflow/vgg_density_001499.png}
		\caption{$t=1499$}
	\end{subfigure}
	\caption{Karman flow simulation trained with VGG-16}
\end{figure}

\begin{figure}
	\centering
	\begin{subfigure}{0.32\textwidth}
		\centering
		\includegraphics[scale=0.49]{karmanflow/l2.png}
		\caption{L2 evaluation}
	\end{subfigure}
	\begin{subfigure}{0.32\textwidth}
		\centering
		\includegraphics[scale=0.49]{karmanflow/l1.png}
		\caption{L1 evaluation}
	\end{subfigure}
	\begin{subfigure}{0.32\textwidth}
		\centering
		\includegraphics[scale=0.49]{karmanflow/mse.png}
		\caption{MSE evaluation}
	\end{subfigure}
	\begin{subfigure}{0.32\textwidth}
		\centering
		\includegraphics[scale=0.49]{karmanflow/lsim.png}
		\caption{LSiM evaluation}
	\end{subfigure}
	\begin{subfigure}{0.32\textwidth}
		\centering
		\includegraphics[scale=0.49]{karmanflow/ssim.png}
		\caption{SSIM evaluation}
	\end{subfigure}
	\begin{subfigure}{0.32\textwidth}
		\centering
		\includegraphics[scale=0.49]{karmanflow/lpips.png}
		\caption{Lpips evaluation}
	\end{subfigure}
	\caption{Numerical evaluation of each metrics on test set with the reference}
\end{figure}

We also tested the karman flow on a lower resolution, whose simulation was running on a 64*64 domain.
The numerical evaluation is a little different than the training on a higher domain. The outputs are similar intuitively, we only show the last frame of each model outputs including the reference and the source simulation.
We can see on a lower domain, Lpips metric outperform the others, while LSiM is the worst over all 4 metrics. However all the metrics has outperformed the source simulation in terms of MSE L2 SSIM and Lpips evaluation, especially in Lpips and L2(MSE) evaluation, every corrected model has made a strong difference comparing to the source simulation.  
\begin{figure}
	\centering
	\begin{subfigure}{0.32\textwidth}
		\centering
		\includegraphics[scale=0.5]{karman_low/ref}
		\caption{Reference}
	\end{subfigure}
	\begin{subfigure}{0.32\textwidth}
		\centering
		\includegraphics[scale=0.5]{karman_low/source}
		\caption{Source}
	\end{subfigure}
	\begin{subfigure}{0.32\textwidth}
		\centering
		\includegraphics[scale=0.5]{karman_low/mse}
		\caption{MSE}
	\end{subfigure}
	\begin{subfigure}{0.32\textwidth}
		\centering
		\includegraphics[scale=0.5]{karman_low/lsim}
		\caption{LSiM}
	\end{subfigure}
	\begin{subfigure}{0.32\textwidth}
		\centering
		\includegraphics[scale=0.5]{karman_low/vgg}
		\caption{VGG-16}
	\end{subfigure}
	\begin{subfigure}{0.32\textwidth}
		\centering
		\includegraphics[scale=0.5]{karman_low/lpips}
		\caption{Lpips}
	\end{subfigure}
	\caption{Karman flow simulation trained with each metric on the 64*64 domain comparing with the reference}
\end{figure}

\begin{figure}
	\centering
	\begin{subfigure}{0.32\textwidth}
		\centering
		\includegraphics[scale=0.49]{karman_low/numeval_l2.png}
		\caption{L2 evaluation}
	\end{subfigure}
	\begin{subfigure}{0.32\textwidth}
		\centering
		\includegraphics[scale=0.49]{karman_low/numeval_l1.png}
		\caption{L1 evaluation}
	\end{subfigure}
	\begin{subfigure}{0.32\textwidth}
		\centering
		\includegraphics[scale=0.49]{karman_low/numeval_mse.png}
		\caption{MSE evaluation}
	\end{subfigure}
	\begin{subfigure}{0.32\textwidth}
		\centering
		\includegraphics[scale=0.49]{karman_low/numeval_lsim.png}
		\caption{LSiM evaluation}
	\end{subfigure}
	\begin{subfigure}{0.32\textwidth}
		\centering
		\includegraphics[scale=0.49]{karman_low/numeval_ssim.png}
		\caption{SSIM evaluation}
	\end{subfigure}
	\begin{subfigure}{0.32\textwidth}
		\centering
		\includegraphics[scale=0.49]{karman_low/numeval_lpips.png}
		\caption{Lpips evaluation}
	\end{subfigure}
	\caption{Numerical evaluation of each metrics on test set with the reference on the 64*64 domain}
\end{figure}

\begin{itemize}
  \item Buoyancy driven flow
\end{itemize}
We first pick a dataset from our training set as the test set with renolds number of 2e5(note the renolds numbers of out training set range from 1e5 to 8e5)
\begin{figure}
\centering
\begin{subfigure}{0.18\textwidth}
  \centering
  \includegraphics[scale=0.28]{buoyancy/dens_000050_ref.png}
  \caption{$t=50$}
\end{subfigure}
\begin{subfigure}{0.18\textwidth}
  \centering
  \includegraphics[scale=0.28]{buoyancy/dens_000100_ref.png}
  \caption{$t=100$}
\end{subfigure}
\begin{subfigure}{0.18\textwidth}
  \centering
  \includegraphics[scale=0.28]{buoyancy/dens_000150_ref.png}
  \caption{$t=150$}
\end{subfigure}
\begin{subfigure}{0.18\textwidth}
  \centering
  \includegraphics[scale=0.28]{buoyancy/dens_000200_ref.png}
  \caption{$t=200$}
\end{subfigure}
\begin{subfigure}{0.18\textwidth}
  \centering
  \includegraphics[scale=0.28]{buoyancy/dens_000249_ref.png}
  \caption{$t=250$}
\end{subfigure}
\caption{Reference simulation}
\end{figure}


\begin{figure}
\centering
\begin{subfigure}{0.18\textwidth}
  \centering
  \includegraphics[scale=0.56]{buoyancy/dens_000050_src.png}
  \caption{$t=50$}
\end{subfigure}
\begin{subfigure}{0.18\textwidth}
  \centering
  \includegraphics[scale=0.56]{buoyancy/dens_000100_src.png}
  \caption{$t=100$}
\end{subfigure}
\begin{subfigure}{0.18\textwidth}
  \centering
  \includegraphics[scale=0.56]{buoyancy/dens_000150_src.png}
  \caption{$t=150$}
\end{subfigure}
\begin{subfigure}{0.18\textwidth}
  \centering
  \includegraphics[scale=0.56]{buoyancy/dens_000200_src.png}
  \caption{$t=200$}
\end{subfigure}
\begin{subfigure}{0.18\textwidth}
  \centering
  \includegraphics[scale=0.56]{buoyancy/dens_000249_src.png}
  \caption{$t=250$}
\end{subfigure}
\caption{Source simulation}
\end{figure}

\begin{figure}
\centering
\begin{subfigure}{0.18\textwidth}
  \centering
  \includegraphics[scale=0.56]{buoyancy/dens_000050_lsim.png}
  \caption{$t=50$}
\end{subfigure}
\begin{subfigure}{0.18\textwidth}
  \centering
  \includegraphics[scale=0.56]{buoyancy/dens_000100_lsim.png}
  \caption{$t=100$}
\end{subfigure}
\begin{subfigure}{0.18\textwidth}
  \centering
  \includegraphics[scale=0.56]{buoyancy/dens_000150_lsim.png}
  \caption{$t=150$}
\end{subfigure}
\begin{subfigure}{0.18\textwidth}
  \centering
  \includegraphics[scale=0.56]{buoyancy/dens_000200_lsim.png}
  \caption{$t=200$}
\end{subfigure}
\begin{subfigure}{0.18\textwidth}
  \centering
  \includegraphics[scale=0.56]{buoyancy/dens_000249_lsim.png}
  \caption{$t=250$}
\end{subfigure}
\caption{simulation with lsim}
\end{figure}

\begin{figure}
\centering
\begin{subfigure}{0.18\textwidth}
  \centering
  \includegraphics[scale=0.56]{buoyancy/dens_000050_mse.png}
  \caption{$t=50$}
\end{subfigure}
\begin{subfigure}{0.18\textwidth}
  \centering
  \includegraphics[scale=0.56]{buoyancy/dens_000100_mse.png}
  \caption{$t=100$}
\end{subfigure}
\begin{subfigure}{0.18\textwidth}
  \centering
  \includegraphics[scale=0.56]{buoyancy/dens_000150_mse.png}
  \caption{$t=150$}
\end{subfigure}
\begin{subfigure}{0.18\textwidth}
  \centering
  \includegraphics[scale=0.56]{buoyancy/dens_000200_mse.png}
  \caption{$t=200$}
\end{subfigure}
\begin{subfigure}{0.18\textwidth}
  \centering
  \includegraphics[scale=0.56]{buoyancy/dens_000249_mse.png}
  \caption{$t=250$}
\end{subfigure}
\caption{simulation with mse}
\end{figure}

\begin{figure}
\centering
\begin{subfigure}{0.18\textwidth}
  \centering
  \includegraphics[scale=0.56]{buoyancy/dens_000050_vgg.png}
  \caption{$t=50$}
\end{subfigure}
\begin{subfigure}{0.18\textwidth}
  \centering
  \includegraphics[scale=0.56]{buoyancy/dens_000100_vgg.png}
  \caption{$t=100$}
\end{subfigure}
\begin{subfigure}{0.18\textwidth}
  \centering
  \includegraphics[scale=0.56]{buoyancy/dens_000150_vgg.png}
  \caption{$t=150$}
\end{subfigure}
\begin{subfigure}{0.18\textwidth}
  \centering
  \includegraphics[scale=0.56]{buoyancy/dens_000200_vgg.png}
  \caption{$t=200$}
\end{subfigure}
\begin{subfigure}{0.18\textwidth}
  \centering
  \includegraphics[scale=0.56]{buoyancy/dens_000249_vgg.png}
  \caption{$t=250$}
\end{subfigure}
\caption{simulation with vgg}
\end{figure}

\begin{figure}
\centering
\begin{subfigure}{0.18\textwidth}
  \centering
  \includegraphics[scale=0.56]{buoyancy/dens_000050_lpips.png}
  \caption{$t=50$}
\end{subfigure}
\begin{subfigure}{0.18\textwidth}
  \centering
  \includegraphics[scale=0.56]{buoyancy/dens_000100_lpips.png}
  \caption{$t=100$}
\end{subfigure}
\begin{subfigure}{0.18\textwidth}
  \centering
  \includegraphics[scale=0.56]{buoyancy/dens_000150_lpips.png}
  \caption{$t=150$}
\end{subfigure}
\begin{subfigure}{0.18\textwidth}
  \centering
  \includegraphics[scale=0.56]{buoyancy/dens_000200_lpips.png}
  \caption{$t=200$}
\end{subfigure}
\begin{subfigure}{0.18\textwidth}
  \centering
  \includegraphics[scale=0.56]{buoyancy/dens_000249_lpips.png}
  \caption{$t=250$}
\end{subfigure}
\caption{simulation with lpips}
\end{figure}

\begin{figure}
\centering
\begin{subfigure}{0.49\textwidth}
  \centering
  \includegraphics[scale=0.4]{buoyancy/l2.png}
  \caption{l2 evaluation}
\end{subfigure}
\begin{subfigure}{0.49\textwidth}
  \centering
  \includegraphics[scale=0.4]{buoyancy/l1.png}
  \caption{l1 evaluation}
\end{subfigure}
\begin{subfigure}{0.49\textwidth}
  \centering
  \includegraphics[scale=0.4]{buoyancy/mse.png}
  \caption{mse evaluation}
\end{subfigure}
\begin{subfigure}{0.49\textwidth}
  \centering
  \includegraphics[scale=0.4]{buoyancy/lsim.png}
  \caption{lsim evaluation}
\end{subfigure}
\begin{subfigure}{0.49\textwidth}
  \centering
  \includegraphics[scale=0.4]{buoyancy/ssim.png}
  \caption{ssim evaluation}
\end{subfigure}
\begin{subfigure}{0.49\textwidth}
  \centering
  \includegraphics[scale=0.4]{buoyancy/lpips.png}
  \caption{lpips evaluation}
\end{subfigure}
\caption{Numerical evaluation of each metrics on training set}
\end{figure}


However when we generate a test set with the renolds number of 2.5e5 which was not included in the training set, the results are then different.
\begin{figure}
\centering
\begin{subfigure}{0.18\textwidth}
  \centering
  \includegraphics[scale=0.28]{buoyancy_test/dens_000050_ref.png}
  \caption{$t=50$}
\end{subfigure}
\begin{subfigure}{0.18\textwidth}
  \centering
  \includegraphics[scale=0.28]{buoyancy_test/dens_000100_ref.png}
  \caption{$t=100$}
\end{subfigure}
\begin{subfigure}{0.18\textwidth}
  \centering
  \includegraphics[scale=0.28]{buoyancy_test/dens_000150_ref.png}
  \caption{$t=150$}
\end{subfigure}
\begin{subfigure}{0.18\textwidth}
  \centering
  \includegraphics[scale=0.28]{buoyancy_test/dens_000200_ref.png}
  \caption{$t=200$}
\end{subfigure}
\begin{subfigure}{0.18\textwidth}
  \centering
  \includegraphics[scale=0.28]{buoyancy_test/dens_000249_ref.png}
  \caption{$t=250$}
\end{subfigure}
\caption{Reference simulation}
\end{figure}

\begin{figure}
\centering
\begin{subfigure}{0.18\textwidth}
  \centering
  \includegraphics[scale=0.56]{buoyancy_test/dens_000050_src.png}
  \caption{$t=50$}
\end{subfigure}
\begin{subfigure}{0.18\textwidth}
  \centering
  \includegraphics[scale=0.56]{buoyancy_test/dens_000100_src.png}
  \caption{$t=100$}
\end{subfigure}
\begin{subfigure}{0.18\textwidth}
  \centering
  \includegraphics[scale=0.56]{buoyancy_test/dens_000150_src.png}
  \caption{$t=150$}
\end{subfigure}
\begin{subfigure}{0.18\textwidth}
  \centering
  \includegraphics[scale=0.56]{buoyancy_test/dens_000200_src.png}
  \caption{$t=200$}
\end{subfigure}
\begin{subfigure}{0.18\textwidth}
  \centering
  \includegraphics[scale=0.56]{buoyancy_test/dens_000249_src.png}
  \caption{$t=250$}
\end{subfigure}
\caption{Source simulation}
\end{figure}

\begin{figure}
\centering
\begin{subfigure}{0.18\textwidth}
  \centering
  \includegraphics[scale=0.56]{buoyancy_test/dens_000050_lsim.png}
  \caption{$t=50$}
\end{subfigure}
\begin{subfigure}{0.18\textwidth}
  \centering
  \includegraphics[scale=0.56]{buoyancy_test/dens_000100_lsim.png}
  \caption{$t=100$}
\end{subfigure}
\begin{subfigure}{0.18\textwidth}
  \centering
  \includegraphics[scale=0.56]{buoyancy_test/dens_000150_lsim.png}
  \caption{$t=150$}
\end{subfigure}
\begin{subfigure}{0.18\textwidth}
  \centering
  \includegraphics[scale=0.56]{buoyancy_test/dens_000200_lsim.png}
  \caption{$t=200$}
\end{subfigure}
\begin{subfigure}{0.18\textwidth}
  \centering
  \includegraphics[scale=0.56]{buoyancy_test/dens_000249_lsim.png}
  \caption{$t=250$}
\end{subfigure}
\caption{simulation with lsim}
\end{figure}

\begin{figure}
\centering
\begin{subfigure}{0.18\textwidth}
  \centering
  \includegraphics[scale=0.56]{buoyancy_test/dens_000050_mse.png}
  \caption{$t=50$}
\end{subfigure}
\begin{subfigure}{0.18\textwidth}
  \centering
  \includegraphics[scale=0.56]{buoyancy_test/dens_000100_mse.png}
  \caption{$t=100$}
\end{subfigure}
\begin{subfigure}{0.18\textwidth}
  \centering
  \includegraphics[scale=0.56]{buoyancy_test/dens_000150_mse.png}
  \caption{$t=150$}
\end{subfigure}
\begin{subfigure}{0.18\textwidth}
  \centering
  \includegraphics[scale=0.56]{buoyancy_test/dens_000200_mse.png}
  \caption{$t=200$}
\end{subfigure}
\begin{subfigure}{0.18\textwidth}
  \centering
  \includegraphics[scale=0.56]{buoyancy_test/dens_000249_mse.png}
  \caption{$t=250$}
\end{subfigure}
\caption{simulation with mse}
\end{figure}

\begin{figure}
\centering
\begin{subfigure}{0.18\textwidth}
  \centering
  \includegraphics[scale=0.56]{buoyancy_test/dens_000050_vgg.png}
  \caption{$t=50$}
\end{subfigure}
\begin{subfigure}{0.18\textwidth}
  \centering
  \includegraphics[scale=0.56]{buoyancy_test/dens_000100_vgg.png}
  \caption{$t=100$}
\end{subfigure}
\begin{subfigure}{0.18\textwidth}
  \centering
  \includegraphics[scale=0.56]{buoyancy_test/dens_000150_vgg.png}
  \caption{$t=150$}
\end{subfigure}
\begin{subfigure}{0.18\textwidth}
  \centering
  \includegraphics[scale=0.56]{buoyancy_test/dens_000200_vgg.png}
  \caption{$t=200$}
\end{subfigure}
\begin{subfigure}{0.18\textwidth}
  \centering
  \includegraphics[scale=0.56]{buoyancy_test/dens_000249_vgg.png}
  \caption{$t=250$}
\end{subfigure}
\caption{simulation with vgg}
\end{figure}

\begin{figure}
\centering
\begin{subfigure}{0.18\textwidth}
  \centering
  \includegraphics[scale=0.56]{buoyancy_test/dens_000050_lpips.png}
  \caption{$t=50$}
\end{subfigure}
\begin{subfigure}{0.18\textwidth}
  \centering
  \includegraphics[scale=0.56]{buoyancy_test/dens_000100_lpips.png}
  \caption{$t=100$}
\end{subfigure}
\begin{subfigure}{0.18\textwidth}
  \centering
  \includegraphics[scale=0.56]{buoyancy_test/dens_000150_lpips.png}
  \caption{$t=150$}
\end{subfigure}
\begin{subfigure}{0.18\textwidth}
  \centering
  \includegraphics[scale=0.56]{buoyancy_test/dens_000200_lpips.png}
  \caption{$t=200$}
\end{subfigure}
\begin{subfigure}{0.18\textwidth}
  \centering
  \includegraphics[scale=0.56]{buoyancy_test/dens_000249_lpips.png}
  \caption{$t=250$}
\end{subfigure}
\caption{simulation with lpips}
\end{figure}
\subsection{Time cost evaluation}

\section{Limitaions}





%------- chapter 6 -------

\chapter{Conclusion}
\section{Future work}
\section{Summary}






\appendix

\chapter{e.g. Questionnaire}

\textit{Note: If you have large models, additional evaluation data like questionnaires or non summarized results, put them into the appendix.}


\clearpage

\clearpage

\listoftables
\clearpage

\bibliography{thesis}
%\bibliographystyle{alpha}
\bibliographystyle{unsrtnat}

\end{document}ison
